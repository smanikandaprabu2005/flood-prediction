PS D:\pers\disaster> python flood_lstm_training.py
2026-01-04 19:41:06.872438: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.       
Sequence shape: (1616, 7, 6)
Label shape   : (1616,)

================ FOLD 1 ================
Train samples: 808
Val samples  : 355
Floods in Val: 80
Class weights: {0: 0.6644736842105263, 1: 2.02}
2026-01-04 19:41:18.819819: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
Epoch 1/50
 1/26 ━━━━━━━━━━━━━━━━━━━━ 3:52 9s/step - auc: 0.4583 - loss: 0.9235 - precision: 0.8148 - recall: 0 5/26 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - auc: 0.3461 - loss: 0.9636 - precision: 0.6081 - recall: 0 9/26 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step - auc: 0.3458 - loss: 1.0152 - precision: 0.4520 - recall: 013/26 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step - auc: 0.3597 - loss: 1.0081 - precision: 0.4111 - recall: 016/26 ━━━━━━━━━━━━━━━━━━━━ 0s 15ms/step - auc: 0.3668 - loss: 0.9987 - precision: 0.3953 - recall: 019/26 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - auc: 0.3749 - loss: 0.9873 - precision: 0.3828 - recall: 022/26 ━━━━━━━━━━━━━━━━━━━━ 0s 17ms/step - auc: 0.3897 - loss: 0.9707 - precision: 0.3723 - recall: 026/26 ━━━━━━━━━━━━━━━━━━━━ 0s 16ms/step - auc: 0.4146 - loss: 0.9436 - precision: 0.3608 - recall:26/26 ━━━━━━━━━━━━━━━━━━━━ 12s 106ms/step - auc: 0.5695 - loss: 0.7754 - precision: 0.2954 - recall: 0.7400 - val_auc: 0.8698 - val_loss: 0.3634 - val_precision: 1.0000 - val_recall: 0.2875
Epoch 2/50
26/26 ━━━━━━━━━━━━━━━━━━━━ 1s 25ms/step - auc: 0.6802 - loss: 0.6551 - precision: 0.3743 - recall: 0.6250 - val_auc: 0.8575 - val_loss: 0.3895 - val_precision: 0.5290 - val_recall: 0.9125
Epoch 3/50
26/26 ━━━━━━━━━━━━━━━━━━━━ 1s 22ms/step - auc: 0.7947 - loss: 0.5456 - precision: 0.4806 - recall: 0.7450 - val_auc: 0.9049 - val_loss: 0.3844 - val_precision: 0.5290 - val_recall: 0.9125
Epoch 4/50
26/26 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - auc: 0.7943 - loss: 0.5360 - precision: 0.4545 - recall: 0.8250 - val_auc: 0.9116 - val_loss: 0.3825 - val_precision: 0.5324 - val_recall: 0.9250
Epoch 5/50
26/26 ━━━━━━━━━━━━━━━━━━━━ 1s 20ms/step - auc: 0.8080 - loss: 0.5160 - precision: 0.4706 - recall: 0.8400 - val_auc: 0.9164 - val_loss: 0.3626 - val_precision: 0.5290 - val_recall: 0.9125
Epoch 6/50
26/26 ━━━━━━━━━━━━━━━━━━━━ 1s 30ms/step - auc: 0.7873 - loss: 0.5402 - precision: 0.4521 - recall: 0.8500 - val_auc: 0.9337 - val_loss: 0.3643 - val_precision: 0.5290 - val_recall: 0.9125
Epoch 7/50
26/26 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - auc: 0.8149 - loss: 0.5054 - precision: 0.4817 - recall: 0.8550 - val_auc: 0.9224 - val_loss: 0.3698 - val_precision: 0.5290 - val_recall: 0.9125
Epoch 8/50
26/26 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - auc: 0.8165 - loss: 0.5014 - precision: 0.4873 - recall: 0.8650 - val_auc: 0.9139 - val_loss: 0.3671 - val_precision: 0.5290 - val_recall: 0.9125
Epoch 9/50
26/26 ━━━━━━━━━━━━━━━━━━━━ 1s 21ms/step - auc: 0.8155 - loss: 0.4971 - precision: 0.4859 - recall: 0.8600 - val_auc: 0.9115 - val_loss: 0.3685 - val_precision: 0.5290 - val_recall: 0.9125
Epoch 10/50
26/26 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - auc: 0.8225 - loss: 0.4951 - precision: 0.4819 - recall: 0.8650 - val_auc: 0.9002 - val_loss: 0.3900 - val_precision: 0.5290 - val_recall: 0.9125
12/12 ━━━━━━━━━━━━━━━━━━━━ 1s 61ms/step 

Confusion Matrix:
[[257  18]
 [ 27  53]]

Classification Report:
              precision    recall  f1-score   support

           0       0.90      0.93      0.92       275
           1       0.75      0.66      0.70        80

    accuracy                           0.87       355
   macro avg       0.83      0.80      0.81       355
weighted avg       0.87      0.87      0.87       355


================ FOLD 2 ================
Train samples: 1163
Val samples  : 323
Floods in Val: 55
Class weights: {0: 0.6585503963759909, 1: 2.0767857142857142}
Epoch 1/50
37/37 ━━━━━━━━━━━━━━━━━━━━ 10s 57ms/step - auc: 0.6388 - loss: 0.6972 - precision: 0.3399 - recall: 0.6179 - val_auc: 0.8994 - val_loss: 0.4266 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00
Epoch 2/50
37/37 ━━━━━━━━━━━━━━━━━━━━ 1s 19ms/step - auc: 0.6622 - loss: 0.6504 - precision: 0.3171 - recall: 0.6286 - val_auc: 0.8998 - val_loss: 0.3641 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00
Epoch 3/50
37/37 ━━━━━━━━━━━━━━━━━━━━ 1s 18ms/step - auc: 0.7541 - loss: 0.5632 - precision: 0.4103 - recall: 0.8250 - val_auc: 0.9016 - val_loss: 0.2884 - val_precision: 0.8140 - val_recall: 0.6364
Epoch 4/50
37/37 ━━━━━━━━━━━━━━━━━━━━ 1s 21ms/step - auc: 0.7903 - loss: 0.5197 - precision: 0.4573 - recall: 0.8607 - val_auc: 0.9118 - val_loss: 0.2783 - val_precision: 0.7273 - val_recall: 0.8727
Epoch 5/50
37/37 ━━━━━━━━━━━━━━━━━━━━ 1s 22ms/step - auc: 0.8364 - loss: 0.4653 - precision: 0.5102 - recall: 0.8893 - val_auc: 0.9161 - val_loss: 0.2922 - val_precision: 0.6575 - val_recall: 0.8727
Epoch 6/50
37/37 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - auc: 0.8435 - loss: 0.4535 - precision: 0.5010 - recall: 0.9214 - val_auc: 0.9190 - val_loss: 0.2451 - val_precision: 0.8333 - val_recall: 0.7273
Epoch 7/50
37/37 ━━━━━━━━━━━━━━━━━━━━ 1s 28ms/step - auc: 0.8320 - loss: 0.4609 - precision: 0.5131 - recall: 0.9107 - val_auc: 0.9220 - val_loss: 0.2403 - val_precision: 0.8519 - val_recall: 0.8364
Epoch 8/50
37/37 ━━━━━━━━━━━━━━━━━━━━ 1s 20ms/step - auc: 0.8441 - loss: 0.4593 - precision: 0.5040 - recall: 0.9107 - val_auc: 0.9269 - val_loss: 0.2410 - val_precision: 0.8222 - val_recall: 0.6727
Epoch 9/50
37/37 ━━━━━━━━━━━━━━━━━━━━ 1s 20ms/step - auc: 0.8296 - loss: 0.4762 - precision: 0.4815 - recall: 0.8821 - val_auc: 0.9130 - val_loss: 0.2850 - val_precision: 0.6076 - val_recall: 0.8727
Epoch 10/50
37/37 ━━━━━━━━━━━━━━━━━━━━ 1s 18ms/step - auc: 0.8516 - loss: 0.4648 - precision: 0.4959 - recall: 0.8536 - val_auc: 0.9172 - val_loss: 0.3382 - val_precision: 0.5647 - val_recall: 0.8727
Epoch 11/50
37/37 ━━━━━━━━━━━━━━━━━━━━ 1s 20ms/step - auc: 0.8498 - loss: 0.4544 - precision: 0.4933 - recall: 0.9250 - val_auc: 0.9331 - val_loss: 0.2510 - val_precision: 0.8519 - val_recall: 0.8364
Epoch 12/50
37/37 ━━━━━━━━━━━━━━━━━━━━ 1s 20ms/step - auc: 0.8531 - loss: 0.4417 - precision: 0.5069 - recall: 0.9214 - val_auc: 0.9350 - val_loss: 0.2281 - val_precision: 0.8545 - val_recall: 0.8545
Epoch 13/50
37/37 ━━━━━━━━━━━━━━━━━━━━ 1s 24ms/step - auc: 0.8569 - loss: 0.4404 - precision: 0.5155 - recall: 0.8929 - val_auc: 0.9269 - val_loss: 0.3051 - val_precision: 0.5854 - val_recall: 0.8727
Epoch 14/50
37/37 ━━━━━━━━━━━━━━━━━━━━ 1s 26ms/step - auc: 0.8672 - loss: 0.4553 - precision: 0.4909 - recall: 0.8679 - val_auc: 0.9360 - val_loss: 0.3343 - val_precision: 0.5333 - val_recall: 0.8727
Epoch 15/50
37/37 ━━━━━━━━━━━━━━━━━━━━ 1s 20ms/step - auc: 0.8452 - loss: 0.4603 - precision: 0.4875 - recall: 0.9036 - val_auc: 0.9437 - val_loss: 0.2716 - val_precision: 0.6857 - val_recall: 0.8727
Epoch 16/50
37/37 ━━━━━━━━━━━━━━━━━━━━ 1s 19ms/step - auc: 0.8629 - loss: 0.4300 - precision: 0.5078 - recall: 0.9286 - val_auc: 0.9446 - val_loss: 0.2334 - val_precision: 0.8545 - val_recall: 0.8545
Epoch 17/50
37/37 ━━━━━━━━━━━━━━━━━━━━ 1s 19ms/step - auc: 0.8748 - loss: 0.4235 - precision: 0.5100 - recall: 0.9107 - val_auc: 0.9421 - val_loss: 0.2706 - val_precision: 0.6316 - val_recall: 0.8727
11/11 ━━━━━━━━━━━━━━━━━━━━ 1s 62ms/step 

Confusion Matrix:
[[251  17]
 [  7  48]]

Classification Report:
              precision    recall  f1-score   support

           0       0.97      0.94      0.95       268
           1       0.74      0.87      0.80        55

    accuracy                           0.93       323
   macro avg       0.86      0.90      0.88       323
weighted avg       0.93      0.93      0.93       323


================ CV SUMMARY ================
Fold 1 → Acc: 0.873, Recall(Flood): 0.662
Fold 2 → Acc: 0.926, Recall(Flood): 0.873

MEAN CV METRICS
Accuracy      : 0.899
Recall(Flood) : 0.768
Epoch 1/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step - auc: 0.4281 - loss: 0.8346 - precision: 0.2506 - recall: 0.4349C:\Users\smani\AppData\Local\Programs\Python\Python310\lib\site-packages\keras\src\callbacks\early_stopping.py:99: UserWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: auc,loss,precision,recall
  current = self.get_monitor_value(logs)
51/51 ━━━━━━━━━━━━━━━━━━━━ 9s 14ms/step - auc: 0.5782 - loss: 0.6536 - precision: 0.2322 - recall: 0.4388
Epoch 2/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 14ms/step - auc: 0.8346 - loss: 0.4711 - precision: 0.4863 - recall: 0.7970
Epoch 3/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - auc: 0.8427 - loss: 0.4450 - precision: 0.5000 - recall: 0.8388
Epoch 4/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - auc: 0.8547 - loss: 0.4223 - precision: 0.5185 - recall: 0.8776
Epoch 5/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - auc: 0.8523 - loss: 0.4381 - precision: 0.4857 - recall: 0.8597
Epoch 6/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 14ms/step - auc: 0.8699 - loss: 0.3999 - precision: 0.5397 - recall: 0.8925
Epoch 7/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - auc: 0.8704 - loss: 0.3969 - precision: 0.5275 - recall: 0.8866 
Epoch 8/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - auc: 0.8726 - loss: 0.3939 - precision: 0.5369 - recall: 0.8896
Epoch 9/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - auc: 0.8739 - loss: 0.4067 - precision: 0.5053 - recall: 0.8567
Epoch 10/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - auc: 0.8791 - loss: 0.3879 - precision: 0.5199 - recall: 0.8985
Epoch 11/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - auc: 0.8862 - loss: 0.3689 - precision: 0.5359 - recall: 0.9134
Epoch 12/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - auc: 0.8823 - loss: 0.3805 - precision: 0.5199 - recall: 0.8985  
Epoch 13/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - auc: 0.8885 - loss: 0.3791 - precision: 0.5034 - recall: 0.8925
Epoch 14/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - auc: 0.8869 - loss: 0.3836 - precision: 0.5263 - recall: 0.8955
Epoch 15/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - auc: 0.9008 - loss: 0.3744 - precision: 0.5198 - recall: 0.8627
Epoch 16/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - auc: 0.9050 - loss: 0.3501 - precision: 0.5405 - recall: 0.8955
Epoch 17/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 12ms/step - auc: 0.9075 - loss: 0.3488 - precision: 0.5247 - recall: 0.8866
Epoch 18/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - auc: 0.9056 - loss: 0.3575 - precision: 0.5154 - recall: 0.8985
Epoch 19/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - auc: 0.8993 - loss: 0.3665 - precision: 0.5105 - recall: 0.8716
Epoch 20/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 16ms/step - auc: 0.9031 - loss: 0.3529 - precision: 0.5232 - recall: 0.9075 
Epoch 21/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 17ms/step - auc: 0.9158 - loss: 0.3330 - precision: 0.5356 - recall: 0.8985  
Epoch 22/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - auc: 0.9178 - loss: 0.3399 - precision: 0.5271 - recall: 0.8985
Epoch 23/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 14ms/step - auc: 0.9170 - loss: 0.3258 - precision: 0.5469 - recall: 0.9045
Epoch 24/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - auc: 0.9224 - loss: 0.3186 - precision: 0.5408 - recall: 0.9104
Epoch 25/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 14ms/step - auc: 0.9213 - loss: 0.3206 - precision: 0.5448 - recall: 0.9075
Epoch 26/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - auc: 0.9221 - loss: 0.3196 - precision: 0.5321 - recall: 0.9164  
Epoch 27/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 16ms/step - auc: 0.8908 - loss: 0.3762 - precision: 0.5130 - recall: 0.8239  
Epoch 28/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 14ms/step - auc: 0.9081 - loss: 0.3534 - precision: 0.5157 - recall: 0.8806
Epoch 29/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - auc: 0.9247 - loss: 0.3183 - precision: 0.5476 - recall: 0.8925
Epoch 30/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - auc: 0.9200 - loss: 0.3225 - precision: 0.5631 - recall: 0.8925
Epoch 31/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 16ms/step - auc: 0.9315 - loss: 0.3035 - precision: 0.5549 - recall: 0.9045 
Epoch 32/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 14ms/step - auc: 0.9393 - loss: 0.2848 - precision: 0.5727 - recall: 0.9284
Epoch 33/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - auc: 0.9314 - loss: 0.3048 - precision: 0.5695 - recall: 0.9045
Epoch 34/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - auc: 0.9062 - loss: 0.3499 - precision: 0.5191 - recall: 0.8537
Epoch 35/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - auc: 0.9298 - loss: 0.3132 - precision: 0.5588 - recall: 0.9075
Epoch 36/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - auc: 0.9254 - loss: 0.3093 - precision: 0.5905 - recall: 0.8866 
Epoch 37/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - auc: 0.9291 - loss: 0.3151 - precision: 0.5315 - recall: 0.9075
Epoch 38/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - auc: 0.9318 - loss: 0.3000 - precision: 0.5447 - recall: 0.9463
Epoch 39/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 17ms/step - auc: 0.9426 - loss: 0.2794 - precision: 0.5652 - recall: 0.9313
Epoch 40/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 16ms/step - auc: 0.9417 - loss: 0.2848 - precision: 0.5659 - recall: 0.9224
Epoch 41/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 17ms/step - auc: 0.9494 - loss: 0.2659 - precision: 0.6258 - recall: 0.9134  
Epoch 42/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 16ms/step - auc: 0.9452 - loss: 0.2781 - precision: 0.5855 - recall: 0.8896 
Epoch 43/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - auc: 0.9499 - loss: 0.2606 - precision: 0.6154 - recall: 0.9313
Epoch 44/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 16ms/step - auc: 0.9446 - loss: 0.2790 - precision: 0.6043 - recall: 0.9164
Epoch 45/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 14ms/step - auc: 0.8451 - loss: 0.4809 - precision: 0.4778 - recall: 0.7075
Epoch 46/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - auc: 0.9223 - loss: 0.3144 - precision: 0.5456 - recall: 0.9284
Epoch 47/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - auc: 0.9361 - loss: 0.2886 - precision: 0.5544 - recall: 0.9433
Epoch 48/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 13ms/step - auc: 0.9433 - loss: 0.2722 - precision: 0.5707 - recall: 0.9403
Epoch 49/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - auc: 0.9243 - loss: 0.3238 - precision: 0.5558 - recall: 0.8627
Epoch 50/50
51/51 ━━━━━━━━━━━━━━━━━━━━ 1s 15ms/step - auc: 0.9361 - loss: 0.2938 - precision: 0.5558 - recall: 0.9075

✅ Final Binary Flood LSTM model saved successfully
